{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6wO7gM5TliEz"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBi7FFLvnZrd",
        "outputId": "3c0eb8e1-0486-4630-edb4-4de864d29fc3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download resource NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ab0qxkTVncv7"
      },
      "outputs": [],
      "source": [
        "# 1. Load dataset\n",
        "df = pd.read_csv('playstore_reviews.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boWEqUDGn59s",
        "outputId": "948550e5-7202-4a6b-9954-9e335ef46ef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jumlah data setelah sampling: 10000\n"
          ]
        }
      ],
      "source": [
        "# Ambil sampel 10.000 ulasan untuk efisiensi\n",
        "df = df.sample(n=10000, random_state=42).reset_index(drop=True)\n",
        "print(f\"Jumlah data setelah sampling: {len(df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD7rkMYvn9a0",
        "outputId": "16feb087-7c51-4f37-a557-6d400c58cb70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distribusi Sentimen:\n",
            "sentiment\n",
            "positive    7978\n",
            "negative    1672\n",
            "neutral      350\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# 2. Pelabelan data berdasarkan rating\n",
        "def label_sentiment(rating):\n",
        "    if rating >= 4:\n",
        "        return 'positive'\n",
        "    elif rating == 3:\n",
        "        return 'neutral'\n",
        "    else:\n",
        "        return 'negative'\n",
        "\n",
        "df['sentiment'] = df['rating'].apply(label_sentiment)\n",
        "\n",
        "# Cek distribusi sentimen\n",
        "print(\"\\nDistribusi Sentimen:\")\n",
        "print(df['sentiment'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "MDDN7au1n_4E"
      },
      "outputs": [],
      "source": [
        "# 3. Preprocessing dan Ekstraksi Fitur\n",
        "stop_words = set(stopwords.words('indonesian'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = str(text).lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [t for t in tokens if t.isalpha() and t not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['processed_text'] = df['text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HZlf-WqCoKDk"
      },
      "outputs": [],
      "source": [
        "# Ekstraksi fitur menggunakan TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X = tfidf.fit_transform(df['processed_text']).toarray()\n",
        "y = df['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "p_p3mG5LoMNF"
      },
      "outputs": [],
      "source": [
        "# 4. 3 skema pelatihan\n",
        "experiments = [\n",
        "    {\n",
        "        'name': 'SVM + TF-IDF + 80/20',\n",
        "        'model': SVC(kernel='linear'),\n",
        "        'train_size': 0.8\n",
        "    },\n",
        "    {\n",
        "        'name': 'RandomForest + TF-IDF + 80/20',\n",
        "        'model': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        'train_size': 0.8\n",
        "    },\n",
        "    {\n",
        "        'name': 'SVM + TF-IDF + 70/30',\n",
        "        'model': SVC(kernel='linear'),\n",
        "        'train_size': 0.7\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDlIIZ2HoPW7",
        "outputId": "da9c1909-8b4f-45a2-82b4-6f224d89b68b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Eksperimen: SVM + TF-IDF + 80/20\n",
            "Akurasi Training: 0.9244\n",
            "Akurasi Testing: 0.8790\n",
            "Laporan Klasifikasi (Testing):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.72      0.64      0.68       334\n",
            "     neutral       0.00      0.00      0.00        70\n",
            "    positive       0.91      0.97      0.94      1596\n",
            "\n",
            "    accuracy                           0.88      2000\n",
            "   macro avg       0.54      0.54      0.54      2000\n",
            "weighted avg       0.84      0.88      0.86      2000\n",
            "\n",
            "\n",
            "Eksperimen: RandomForest + TF-IDF + 80/20\n",
            "Akurasi Training: 0.9869\n",
            "Akurasi Testing: 0.8680\n",
            "Laporan Klasifikasi (Testing):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.70      0.62      0.66       334\n",
            "     neutral       0.00      0.00      0.00        70\n",
            "    positive       0.90      0.96      0.93      1596\n",
            "\n",
            "    accuracy                           0.87      2000\n",
            "   macro avg       0.53      0.53      0.53      2000\n",
            "weighted avg       0.83      0.87      0.85      2000\n",
            "\n",
            "\n",
            "Eksperimen: SVM + TF-IDF + 70/30\n",
            "Akurasi Training: 0.9246\n",
            "Akurasi Testing: 0.8673\n",
            "Laporan Klasifikasi (Testing):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.69      0.61      0.65       502\n",
            "     neutral       0.00      0.00      0.00       105\n",
            "    positive       0.90      0.96      0.93      2393\n",
            "\n",
            "    accuracy                           0.87      3000\n",
            "   macro avg       0.53      0.52      0.53      3000\n",
            "weighted avg       0.83      0.87      0.85      3000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 5. Eksperimen Utama\n",
        "results = []\n",
        "for exp in experiments:\n",
        "    print(f\"\\nEksperimen: {exp['name']}\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, train_size=exp['train_size'], random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Latih model\n",
        "    model = exp['model']\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluasi\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "    print(f\"Akurasi Training: {train_accuracy:.4f}\")\n",
        "    print(f\"Akurasi Testing: {test_accuracy:.4f}\")\n",
        "    print(\"Laporan Klasifikasi (Testing):\")\n",
        "    print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "    results.append({\n",
        "        'name': exp['name'],\n",
        "        'train_accuracy': train_accuracy,\n",
        "        'test_accuracy': test_accuracy\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1redc3yG0brA",
        "outputId": "47ebea80-f5e8-4a89-9566-ff30c6e79518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Contoh Inference:\n"
          ]
        }
      ],
      "source": [
        "# 6. Inference\n",
        "print(\"\\nContoh Inference:\")\n",
        "sample_texts = [\n",
        "    \"Aplikasi ini sangat membantu, pengiriman cepat!\",\n",
        "    \"Fitur lumayan, tapi kadang error.\",\n",
        "    \"Sangat buruk, aplikasi sering crash.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9KzA7a49qmta"
      },
      "outputs": [],
      "source": [
        "# Preprocess dan transform\n",
        "sample_processed = [preprocess_text(text) for text in sample_texts]\n",
        "sample_tfidf = tfidf.transform(sample_processed).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "mc09xtldqo0L"
      },
      "outputs": [],
      "source": [
        "# Prediksi menggunakan model terbaik (dari eksperimen pertama)\n",
        "best_model = experiments[0]['model']\n",
        "best_model.fit(X, y)  # Latih ulang pada seluruh data untuk inference\n",
        "predictions = best_model.predict(sample_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgGoa79zrIJa",
        "outputId": "804b9ec5-82f5-4db1-b1d4-af302c0de5d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teks: Aplikasi ini sangat membantu, pengiriman cepat!\n",
            "Sentimen: positive\n",
            "\n",
            "Teks: Fitur lumayan, tapi kadang error.\n",
            "Sentimen: positive\n",
            "\n",
            "Teks: Sangat buruk, aplikasi sering crash.\n",
            "Sentimen: negative\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Tampilkan hasil\n",
        "for text, pred in zip(sample_texts, predictions):\n",
        "    print(f\"Teks: {text}\")\n",
        "    print(f\"Sentimen: {pred}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK1e84acrNpi",
        "outputId": "9985894a-5d31-4dfa-e0ef-d7f3e2010d82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Ringkasan Hasil Eksperimen:\n",
            "                            name  train_accuracy  test_accuracy\n",
            "0           SVM + TF-IDF + 80/20        0.924375       0.879000\n",
            "1  RandomForest + TF-IDF + 80/20        0.986875       0.868000\n",
            "2           SVM + TF-IDF + 70/30        0.924571       0.867333\n"
          ]
        }
      ],
      "source": [
        "# 7. Simpan hasil eksperimen\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nRingkasan Hasil Eksperimen:\")\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "97xe7_N7rQsT"
      },
      "outputs": [],
      "source": [
        "# 8. Simpan dataset yang sudah diproses (opsional)\n",
        "df[['text', 'rating', 'sentiment', 'processed_text']].to_csv('processed_reviews.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
